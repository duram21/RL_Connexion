#!/usr/bin/env python3
import sys
import os
import random
import copy

# â˜… ì´ˆê¸° ì‹¤í–‰ ì†ë„ë¥¼ ìœ„í•´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì§€ì—° ë¡œë”© (Lazy Import)

def main():
    model = None
    device = None
    torch = None
    np = None
    
    # ------------------------------------------------------------------
    # 1. ê°€ë²¼ìš´ ìƒìˆ˜/í•¨ìˆ˜ ì •ì˜ (Env ì˜ì¡´ì„± ì—†ì´ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡)
    # ------------------------------------------------------------------
    colors = ['R', 'G', 'B', 'Y']
    symbols = ['1', '2', '3', '4']
    
    valid_cells = []
    forbidden = {"a1-", "a4-", "c3+", "c6+", "d1-", "d4-", "f3+", "f6+"}
    for c in ['a','b','c','d','e','f']:
        for r in ['1','2','3','4','5','6']:
            for s in ['-', '+']:
                if (c+r+s) not in forbidden: valid_cells.append(c+r+s)
    
    cell_to_idx = {s: i for i, s in enumerate(valid_cells)}

    def parse_tile(s):
        if s == "X0": return None
        try: return colors.index(s[0]) * 4 + symbols.index(s[1])
        except: return None

    def get_tile_str(tid):
        return colors[tid//4] + symbols[tid%4]

    # ìƒíƒœ ë³€ìˆ˜
    my_hand = []
    board_state = [-1] * 64
    env_sim = None

    # ------------------------------------------------------------------
    # 2. í•˜ì´ë¸Œë¦¬ë“œ ë¡œì§ (PPO + Greedy)
    # ------------------------------------------------------------------
    def get_hybrid_action(model, env, obs, mask, device, torch, np):
        """
        PPOì˜ ì§ê´€ê³¼ Greedyì˜ ê³„ì‚°ì„ í•©ì³ì„œ ìµœì ì˜ ìˆ˜ë¥¼ ê²°ì •
        """
        # 1. PPOì˜ ì¶”ì²œ (ì§ê´€)
        obs_t = torch.tensor(obs).float().unsqueeze(0).to(device)
        mask_t = torch.tensor(mask).bool().unsqueeze(0).to(device)
        
        with torch.no_grad():
            # Actorì˜ Logit ê³„ì‚°
            x, h = model.forward_shared(obs_t)
            b = x.size(0)
            pol = torch.nn.functional.relu(model.actor_bn(model.actor_conv(x))).view(b, -1)
            pol = torch.cat([pol, h], dim=1)
            logits = model.actor_fc(pol)
            
            # ë§ˆìŠ¤í‚¹ í›„ ê°€ì¥ í™•ë¥  ë†’ì€ ìˆ˜ ì„ íƒ
            logits = logits.masked_fill(~mask_t, -1e9)
            ppo_action = torch.argmax(logits, dim=1).item()

        # 2. Greedyì˜ ì¶”ì²œ (ê³„ì‚°)
        greedy_action, greedy_score = find_best_greedy_move(env)
        
        # 3. PPO ìˆ˜ì˜ ì ìˆ˜ ì‹œë®¬ë ˆì´ì…˜
        ppo_score = simulate_score(env, ppo_action)
        
        # 4. ìµœì¢… ê²°ì • (Hybrid)
        # Greedyê°€ PPOë³´ë‹¤ 5ì  ì´ìƒ ë” ë†’ìœ¼ë©´ "PPOê°€ ì‹¤ìˆ˜í–ˆë‹¤"ê³  íŒë‹¨í•˜ê³  Greedyë¥¼ ë”°ë¦„
        # ê·¸ ì™¸ì—ëŠ” PPOì˜ "í° ê·¸ë¦¼"ì„ ì¡´ì¤‘
        if greedy_score > ppo_score + 5.0:
            return greedy_action
        else:
            return ppo_action

    def find_best_greedy_move(env):
        best_val = -9999
        best_action = -1
        
        # ê°€ëŠ¥í•œ ëª¨ë“  ìˆ˜ íƒìƒ‰
        for slot in range(len(env.agent_hand)):
            for c_idx in range(64):
                if env.board[c_idx] == -1:
                    action = slot * 64 + c_idx
                    val = simulate_score(env, action)
                    
                    if val > best_val:
                        best_val = val
                        best_action = action
                        
        # ë§Œì•½ ë‘˜ ê³³ì´ ì—†ìœ¼ë©´(ë“œë¬¼ì§€ë§Œ) 0ë²ˆ ë¦¬í„´
        if best_action == -1: return 0, -9999
        return best_action, best_val

    def simulate_score(env, action):
        # ì‹œë®¬ë ˆì´ì…˜ì„ ìœ„í•œ ë°±ì—… (Deepcopyë³´ë‹¤ ë¦¬ìŠ¤íŠ¸ ìŠ¬ë¼ì´ì‹±ì´ ë¹ ë¦„)
        backup_board = list(env.board)
        backup_hand = list(env.agent_hand)
        backup_filled = env.filled
        
        slot = action // 64
        c_idx = action % 64
        
        # ìœ íš¨ì„± ì²´í¬
        if slot >= len(env.agent_hand) or env.board[c_idx] != -1:
            return -9999 # ë¶ˆê°€ëŠ¥í•œ ìˆ˜
            
        # ê°€ìƒ ì°©ìˆ˜
        tid = env.agent_hand.pop(slot)
        env.board[c_idx] = tid
        env.filled += 1
        
        # ì ìˆ˜ ê³„ì‚° (ë‚´ ì ìˆ˜ - ìƒëŒ€ ì ìˆ˜)
        # ConnexionEnv ë‚´ë¶€ í•¨ìˆ˜ í™œìš©
        fs, ss, diff = env._compute_scores()
        
        # ë³µêµ¬
        env.board = backup_board
        env.agent_hand = backup_hand
        env.filled = backup_filled
        
        return diff

    # ------------------------------------------------------------------
    # 3. ë©”ì¸ ë£¨í”„
    # ------------------------------------------------------------------
    while True:
        try:
            line = sys.stdin.readline()
            if not line: break
            parts = line.strip().split()
            if not parts: continue
            cmd = parts[0]

            if cmd == "READY":
                # TLE ë°©ì§€: ì¼ë‹¨ OK ë³´ë‚´ê³  ë¡œë”© ì‹œì‘
                print("OK")
                sys.stdout.flush()
                
                if model is None:
                    import torch as t
                    import torch.nn as nn
                    import torch.nn.functional as F
                    import numpy as n
                    from connexion_env import ConnexionEnv 
                    
                    torch = t
                    np = n
                    torch.set_num_threads(1) # CPU ì ìœ ìœ¨ ìµœì í™”
                    
                    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ResNet êµ¬ì¡° (í•™ìŠµ ì½”ë“œì™€ ë™ì¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    class ResBlock(nn.Module):
                        def __init__(self, channels):
                            super().__init__()
                            self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False)
                            self.bn1 = nn.BatchNorm2d(channels)
                            self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False)
                            self.bn2 = nn.BatchNorm2d(channels)

                        def forward(self, x):
                            residual = x
                            out = F.relu(self.bn1(self.conv1(x)))
                            out = self.bn2(self.conv2(out))
                            out += residual
                            return F.relu(out)

                    class ActorCritic(nn.Module):
                        def __init__(self, obs_dim, act_dim):
                            super(ActorCritic, self).__init__()
                            
                            self.conv_in = nn.Conv2d(16, 128, kernel_size=3, stride=1, padding=1, bias=False)
                            self.bn_in = nn.BatchNorm2d(128)
                            
                            # 5-Layer ResNet
                            self.res_blocks = nn.Sequential(
                                ResBlock(128), ResBlock(128), ResBlock(128), ResBlock(128), ResBlock(128)
                            )
                            
                            self.fc_hand = nn.Sequential(nn.Linear(80, 128), nn.ReLU())
                            
                            # Actor Head
                            self.actor_conv = nn.Conv2d(128, 32, kernel_size=1)
                            self.actor_bn = nn.BatchNorm2d(32)
                            self.actor_fc = nn.Linear(32 * 8 * 8 + 128, act_dim)
                            
                            # Critic Head (êµ¬ì¡° ë§ì¶”ê¸°ìš©)
                            self.critic_conv = nn.Conv2d(128, 8, kernel_size=1)
                            self.critic_bn = nn.BatchNorm2d(8)
                            self.critic_fc1 = nn.Linear(8 * 8 * 8 + 128, 256)
                            self.critic_fc2 = nn.Linear(256, 1)

                        def forward_shared(self, obs):
                            b = obs.size(0)
                            board = obs[:, :1024].view(b, 64, 16).permute(0, 2, 1).contiguous().view(b, 16, 8, 8)
                            hand = obs[:, 1024:]
                            x = F.relu(self.bn_in(self.conv_in(board)))
                            x = self.res_blocks(x)
                            h = self.fc_hand(hand)
                            return x, h

                    device = torch.device("cpu")
                    model = ActorCritic(1104, 320).to(device)
                    
                    # ëª¨ë¸ ë¡œë“œ (ì—†ìœ¼ë©´ ì´ˆê¸°í™” ìƒíƒœë¡œ ì§„í–‰ -> ê·¸ë˜ë„ Greedy ë¡œì§ ë•ë¶„ì— ì˜í•¨)
                    model_path = "best_model.pt"
                    if not os.path.exists(model_path): model_path = "final_model.pt"
                    
                    if os.path.exists(model_path):
                        try: model.load_state_dict(torch.load(model_path, map_location=device))
                        except: pass
                    model.eval()
                    
                    # Env ì‹œë®¬ë ˆì´í„° ì´ˆê¸°í™”
                    env_sim = ConnexionEnv()

                    # ì›Œë°ì—… (ì²« í„´ ë ‰ ë°©ì§€)
                    with torch.no_grad():
                        dummy_obs = torch.zeros(1, 1104).to(device)
                        _ = model.forward_shared(dummy_obs)

            elif cmd == "INIT":
                my_hand = [parse_tile(t) for t in parts[1:6]]
                board_state = [-1] * 64
                if env_sim:
                    env_sim.reset()
                    env_sim.agent_hand = my_hand[:]
                    env_sim.board = board_state[:]

            elif cmd == "TIME":
                obs = np.zeros(1104, dtype=np.float32)
                for i in range(64):
                    if board_state[i] != -1: obs[i*16 + board_state[i]] = 1.0
                for i in range(5):
                    if i < len(my_hand): obs[1024 + i*16 + my_hand[i]] = 1.0
                
                # í•˜ì´ë¸Œë¦¬ë“œ ê²°ì • (PPO + Greedy)
                if env_sim:
                    env_sim.board = board_state[:]
                    env_sim.agent_hand = my_hand[:]
                    env_sim.filled = sum(1 for x in board_state if x != -1)
                    mask = env_sim.get_smart_action_mask()
                    
                    # ğŸ”¥ [í•µì‹¬] Hybrid Action Selection
                    action = get_hybrid_action(model, env_sim, obs, mask, device, torch, np)
                else:
                    action = 0 # Fallback

                slot, c_idx = action // 64, action % 64
                
                # ğŸ›¡ï¸ [ìµœì¢… ì•ˆì „ì¥ì¹˜] ì´ë¯¸ ì°¬ ê³³ì´ë©´ ë¹ˆ ê³³ ì°¾ê¸° (NOT EMPTY ì—ëŸ¬ ë°©ì§€)
                if board_state[c_idx] != -1:
                    for i in range(64):
                        if board_state[i] == -1:
                            c_idx = i; slot = 0; break
                            
                if slot >= len(my_hand): slot = 0
                
                print(f"PUT {valid_cells[c_idx]} {get_tile_str(my_hand[slot])}")
                sys.stdout.flush()
                
                board_state[c_idx] = my_hand.pop(slot)

            elif cmd == "GET":
                new_t = parse_tile(parts[1])
                if new_t is not None: my_hand.append(new_t)

            elif cmd == "OPP":
                c_idx = cell_to_idx.get(parts[1])
                if c_idx is not None: board_state[c_idx] = parse_tile(parts[2])

            elif cmd == "FINISH":
                break

        except Exception:
            break

if __name__ == "__main__":
    main()